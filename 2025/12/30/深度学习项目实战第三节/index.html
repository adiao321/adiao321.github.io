<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1.0,viewport-fit=cover"><title>深度学习项目实战第三节 | 何意味</title><meta name="author" content="线粒体donut"><meta name="copyright" content="线粒体donut"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta name="description" content="首先我们要新建一个类，一个类里面要有三部分 第一部分：初始化第一，打开文件123456def __init__(____________):    with open(file_train,&quot;r&quot;) as f:        csv_data &#x3D; list(csv.reader(file_train))        column &#x3D; csv_data[0]        x">
<meta property="og:type" content="article">
<meta property="og:title" content="深度学习项目实战第三节">
<meta property="og:url" content="http://example.com/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/index.html">
<meta property="og:site_name" content="何意味">
<meta property="og:description" content="首先我们要新建一个类，一个类里面要有三部分 第一部分：初始化第一，打开文件123456def __init__(____________):    with open(file_train,&quot;r&quot;) as f:        csv_data &#x3D; list(csv.reader(file_train))        column &#x3D; csv_data[0]        x">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://example.com/img/picture.jpg">
<meta property="article:published_time" content="2025-12-30T03:19:54.000Z">
<meta property="article:modified_time" content="2026-01-01T14:49:27.188Z">
<meta property="article:author" content="线粒体donut">
<meta property="article:tag" content="回归">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://example.com/img/picture.jpg"><script type="application/ld+json">{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "深度学习项目实战第三节",
  "url": "http://example.com/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/",
  "image": "http://example.com/img/picture.jpg",
  "datePublished": "2025-12-30T03:19:54.000Z",
  "dateModified": "2026-01-01T14:49:27.188Z",
  "author": [
    {
      "@type": "Person",
      "name": "线粒体donut",
      "url": "http://example.com"
    }
  ]
}</script><link rel="shortcut icon" href="/img/picture.jpg"><link rel="canonical" href="http://example.com/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/index.html"><link rel="preconnect" href="//cdn.jsdelivr.net"/><link rel="preconnect" href="//busuanzi.ibruce.info"/><link rel="stylesheet" href="/css/index.css?v=5.5.3"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@7.1.0/css/all.min.css"><script>
    (() => {
      
    const saveToLocal = {
      set: (key, value, ttl) => {
        if (!ttl) return
        const expiry = Date.now() + ttl * 86400000
        localStorage.setItem(key, JSON.stringify({ value, expiry }))
      },
      get: key => {
        const itemStr = localStorage.getItem(key)
        if (!itemStr) return undefined
        const { value, expiry } = JSON.parse(itemStr)
        if (Date.now() > expiry) {
          localStorage.removeItem(key)
          return undefined
        }
        return value
      }
    }

    window.btf = {
      saveToLocal,
      getScript: (url, attr = {}) => new Promise((resolve, reject) => {
        const script = document.createElement('script')
        script.src = url
        script.async = true
        Object.entries(attr).forEach(([key, val]) => script.setAttribute(key, val))
        script.onload = script.onreadystatechange = () => {
          if (!script.readyState || /loaded|complete/.test(script.readyState)) resolve()
        }
        script.onerror = reject
        document.head.appendChild(script)
      }),
      getCSS: (url, id) => new Promise((resolve, reject) => {
        const link = document.createElement('link')
        link.rel = 'stylesheet'
        link.href = url
        if (id) link.id = id
        link.onload = link.onreadystatechange = () => {
          if (!link.readyState || /loaded|complete/.test(link.readyState)) resolve()
        }
        link.onerror = reject
        document.head.appendChild(link)
      }),
      addGlobalFn: (key, fn, name = false, parent = window) => {
        if (!false && key.startsWith('pjax')) return
        const globalFn = parent.globalFn || {}
        globalFn[key] = globalFn[key] || {}
        globalFn[key][name || Object.keys(globalFn[key]).length] = fn
        parent.globalFn = globalFn
      }
    }
  
      
      const activateDarkMode = () => {
        document.documentElement.setAttribute('data-theme', 'dark')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#0d0d0d')
        }
      }
      const activateLightMode = () => {
        document.documentElement.setAttribute('data-theme', 'light')
        if (document.querySelector('meta[name="theme-color"]') !== null) {
          document.querySelector('meta[name="theme-color"]').setAttribute('content', '#ffffff')
        }
      }

      btf.activateDarkMode = activateDarkMode
      btf.activateLightMode = activateLightMode

      const theme = saveToLocal.get('theme')
    
          theme === 'dark' ? activateDarkMode() : theme === 'light' ? activateLightMode() : null
        
      
      const asideStatus = saveToLocal.get('aside-status')
      if (asideStatus !== undefined) {
        document.documentElement.classList.toggle('hide-aside', asideStatus === 'hide')
      }
    
      
    const detectApple = () => {
      if (/iPad|iPhone|iPod|Macintosh/.test(navigator.userAgent)) {
        document.documentElement.classList.add('apple')
      }
    }
    detectApple()
  
    })()
  </script><script>const GLOBAL_CONFIG = {
  root: '/',
  algolia: undefined,
  localSearch: {"path":"/search.xml","preload":false,"top_n_per_article":1,"unescape":false,"pagination":{"enable":false,"hitsPerPage":8},"languages":{"hits_empty":"未找到符合您查询的内容：${query}","hits_stats":"共找到 ${hits} 篇文章"}},
  translate: undefined,
  highlight: {"plugin":"highlight.js","highlightCopy":true,"highlightLang":true,"highlightHeightLimit":false,"highlightFullpage":false,"highlightMacStyle":false},
  copy: {
    success: '复制成功',
    error: '复制失败',
    noSupport: '浏览器不支持'
  },
  relativeDate: {
    homepage: false,
    post: false
  },
  runtime: '',
  dateSuffix: {
    just: '刚刚',
    min: '分钟前',
    hour: '小时前',
    day: '天前',
    month: '个月前'
  },
  copyright: undefined,
  lightbox: 'null',
  Snackbar: undefined,
  infinitegrid: {
    js: 'https://cdn.jsdelivr.net/npm/@egjs/infinitegrid@4.12.0/dist/infinitegrid.min.js',
    buttonText: '加载更多'
  },
  isPhotoFigcaption: false,
  islazyloadPlugin: false,
  isAnchor: false,
  percent: {
    toc: true,
    rightside: false,
  },
  autoDarkmode: false
}</script><script id="config-diff">var GLOBAL_CONFIG_SITE = {
  title: '深度学习项目实战第三节',
  isHighlightShrink: false,
  isToc: true,
  pageType: 'post'
}</script><meta name="generator" content="Hexo 8.1.1"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="avatar-img text-center"><img src="/img/picture.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="site-data text-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header"><nav id="nav"><span id="blog-info"><a class="nav-site-title" href="/"><span class="site-name">何意味</span></a><a class="nav-page-title" href="/"><span class="site-name">深度学习项目实战第三节</span><span class="site-name"><i class="fa-solid fa-circle-arrow-left"></i><span>  返回首页</span></span></a></span><div id="menus"><div id="search-button"><span class="site-page social-icon search"><i class="fas fa-search fa-fw"></i><span> 搜索</span></span></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i><span> 主页</span></a></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fa fa-graduation-cap"></i><span> 博文</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/categories/"><i class="fa-fw fa fa-archive"></i><span> 分类</span></a></li><li><a class="site-page child" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></li><li><a class="site-page child" href="/archives/"><i class="fa-fw fa fa-folder-open"></i><span> 归档</span></a></li></ul></div><div class="menus_item"><span class="site-page group"><i class="fa-fw fas fa-list"></i><span> 生活</span><i class="fas fa-chevron-down"></i></span><ul class="menus_item_child"><li><a class="site-page child" href="/shuoshuo/"><i class="fa-fw fa fa-comments-o"></i><span> 分享</span></a></li><li><a class="site-page child" href="/photos/"><i class="fa-fw fa fa-camera-retro"></i><span> 相册</span></a></li><li><a class="site-page child" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page child" href="/movies/"><i class="fa-fw fas fa-video"></i><span> 影视</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/links/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/comment/"><i class="fa-fw fa fa-paper-plane"></i><span> 留言板</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fas fa-heart"></i><span> 关于笔者</span></a></div></div><div id="toggle-menu"><span class="site-page"><i class="fas fa-bars fa-fw"></i></span></div></div></nav><div id="post-info"><h1 class="post-title">深度学习项目实战第三节</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2025-12-30T03:19:54.000Z" title="发表于 2025-12-30 11:19:54">2025-12-30</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2026-01-01T14:49:27.188Z" title="更新于 2026-01-01 22:49:27">2026-01-01</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/">深度学习</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">总字数:</span><span class="word-count">2.1k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>8分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv" id="" data-flag-title=""><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">浏览量:</span><span id="busuanzi_value_page_pv"><i class="fa-solid fa-spinner fa-spin"></i></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="container post-content" id="article-container"><p>首先我们要新建一个类，一个类里面要有三部分</p>
<h1 id="第一部分：初始化"><a href="#第一部分：初始化" class="headerlink" title="第一部分：初始化"></a>第一部分：初始化</h1><h2 id="第一，打开文件"><a href="#第一，打开文件" class="headerlink" title="第一，打开文件"></a>第一，打开文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">____________</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_train,<span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        csv_data = <span class="built_in">list</span>(csv.reader(file_train))</span><br><span class="line">        column = csv_data[<span class="number">0</span>]</span><br><span class="line">        x = csv_data[<span class="number">1</span>:, <span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">        y = csv_data[<span class="number">1</span>:, -<span class="number">1</span>]</span><br></pre></td></tr></table></figure>

<h3 id="一、with-open-file-train-”r”-as-f中的with和as-f是干嘛用的？"><a href="#一、with-open-file-train-”r”-as-f中的with和as-f是干嘛用的？" class="headerlink" title="一、with open(file_train,”r”) as f中的with和as f是干嘛用的？"></a>一、with open(file_train,”r”) as f中的with和as f是干嘛用的？</h3><p>with：自动关闭文件。相当于open()打开而自动使用close()关闭。若只open不close，会导致文件一直被程序占用，其他程序无法打开导致内存泄漏。</p>
<p>as f：相当于给文件命名</p>
<h3 id="二、为什么需要list-？"><a href="#二、为什么需要list-？" class="headerlink" title="二、为什么需要list()？"></a>二、为什么需要list()？</h3><p>因为csv.reader()的作用是按照行分隔符（“&#x2F;n”）和列分隔符（“，”）做切割，如</p>
<p><img src="/images/1.png" alt="image-20251230181802459"></p>
<p>但这个功能是一个迭代器，只能单向遍历一次，不能索引，故需要转换成list以便于直接访问</p>
<h2 id="第二，特征筛选（可选）"><a href="#第二，特征筛选（可选）" class="headerlink" title="第二，特征筛选（可选）"></a>第二，特征筛选（可选）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_feature_importance</span>(<span class="params">feature_data, label_data, k =<span class="number">4</span>,column = <span class="literal">None</span></span>):</span><br><span class="line">    model = SelectKBest(chi2, k=k)      <span class="comment">#定义一个选择k个最佳特征的函数</span></span><br><span class="line">    feature_data = np.array(feature_data, dtype=np.float64)</span><br><span class="line">    X_new = model.fit_transform(feature_data, label_data)   <span class="comment">#用这个函数选择k个最佳特征</span></span><br><span class="line">    <span class="comment">#feature_data是特征数据，label_data是标签数据，该函数可以选择出k个特征</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x_new&#x27;</span>, X_new)</span><br><span class="line">    scores = model.scores_                <span class="comment"># scores即每一列与结果的相关性</span></span><br><span class="line">    <span class="comment"># 按重要性排序，选出最重要的 k 个</span></span><br><span class="line">    indices = np.argsort(scores)[::-<span class="number">1</span>]        <span class="comment">#[::-1]表示反转一个列表或者矩阵。</span></span><br><span class="line">    <span class="comment"># argsort这个函数， 可以矩阵排序后的下标。 比如 indices[0]表示的是，scores中最小值的下标。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> column:                            <span class="comment"># 如果需要打印选中的列</span></span><br><span class="line">        k_best_features = [column[i+<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> indices[<span class="number">0</span>:k].tolist()]         <span class="comment"># 选中这些列 打印</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;k best features are: &#x27;</span>,k_best_features)</span><br><span class="line">    <span class="keyword">return</span> X_new, indices[<span class="number">0</span>:k]                  <span class="comment"># 返回选中列的特征和他们的下标。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> all_feature:</span><br><span class="line">                col_indices = np.array([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">93</span>)])</span><br><span class="line">                col_indices = col_indices.tolist()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                _,col_indices = get_feature_importance(x,y,feature_dim,column)</span><br><span class="line">                col_indices = col_indices.tolist()</span><br><span class="line">                </span><br><span class="line">            csv_data = np.array(csv_data[<span class="number">1</span>:])[:, <span class="number">1</span>:].astype(<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure>

<h3 id="feature-data-label-data分别是什么参数？"><a href="#feature-data-label-data分别是什么参数？" class="headerlink" title="feature_data, label_data分别是什么参数？"></a>feature_data, label_data分别是什么参数？</h3><p>是x和y，即用来训练的数据部分和用来训练的已知的训练结果标签</p>
<h2 id="第三，拆分数据集（只处理了y）"><a href="#第三，拆分数据集（只处理了y）" class="headerlink" title="第三，拆分数据集（只处理了y）"></a>第三，拆分数据集（只处理了y）</h2><p>训练集逢五取四，验证集逢五取一，测试集全取。</p>
<p>y是训练、验证的标签，由于是这个类里面其他函数也要用的部分，故用self.y变成全局的。由于要后续使用，故转换成tensor</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">    indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(csv_data)) <span class="keyword">if</span> i % <span class="number">5</span> !=<span class="number">0</span>]</span><br><span class="line">    <span class="variable language_">self</span>.y = torch.tensor(csv_data[indices,-<span class="number">1</span>])</span><br><span class="line"><span class="keyword">elif</span> mode == <span class="string">&quot;val&quot;</span>:</span><br><span class="line">    indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(csv_data)) <span class="keyword">if</span> i % <span class="number">5</span> ==<span class="number">0</span>]</span><br><span class="line">    <span class="variable language_">self</span>.y = torch.tensor(csv_data[indices,-<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(csv_data))]</span><br></pre></td></tr></table></figure>

<h2 id="第四，特征提取（处理x），归一化，校验"><a href="#第四，特征提取（处理x），归一化，校验" class="headerlink" title="第四，特征提取（处理x），归一化，校验"></a>第四，特征提取（处理x），归一化，校验</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = torch.tensor(csv_data[indices,:])	<span class="comment"># 只取选中模式（训练、验证、测试）下的行</span></span><br><span class="line">data = torch.tensor(csv_data[:,col_indices])	<span class="comment">#只取挑出来的列</span></span><br><span class="line"><span class="variable language_">self</span>.data = data</span><br><span class="line"><span class="variable language_">self</span>.mode = mode</span><br><span class="line"><span class="variable language_">self</span>.data = (<span class="variable language_">self</span>.data - <span class="variable language_">self</span>.data.mean(dim=<span class="number">0</span>,keepdim=<span class="literal">True</span>)) / <span class="variable language_">self</span>.data.std(dim=<span class="number">0</span>,keepdim=<span class="literal">True</span>)	<span class="comment"># 归一化</span></span><br><span class="line"><span class="keyword">assert</span> feature_dim == <span class="variable language_">self</span>.data.shape[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished reading the &#123;&#125; set of COVID19 Dataset (&#123;&#125; samples found, each dim = &#123;&#125;)&#x27;</span>.<span class="built_in">format</span>(mode, <span class="built_in">len</span>(<span class="variable language_">self</span>.data), feature_dim))  <span class="comment"># 打印读了多少数据</span></span><br></pre></td></tr></table></figure>

<h3 id="归一化？"><a href="#归一化？" class="headerlink" title="归一化？"></a>归一化？</h3><p><strong>标准化（Z-Score）公式</strong></p>
<p>这段代码实现的归一化遵循严格的数学公式：</p>
<p>$X_{norm} &#x3D; \frac{X - \mu}{\sigma}$</p>
<p>其中：</p>
<ul>
<li><em>X</em>：原始特征数据（这里是 <code>self.data</code> 张量中的某个特征的所有样本值）</li>
<li><em>μ</em>（mu）：该特征的<strong>均值</strong>（所有样本在该特征上的平均值，对应代码中 <code>self.data.mean(dim=0, keepdim=True)</code>）</li>
<li><em>σ</em>（sigma）：该特征的<strong>标准差</strong>（所有样本在该特征上的离散程度，对应代码中 <code>self.data.std(dim=0, keepdim=True)</code>）</li>
<li><strong>X</strong>norm：标准化后的特征数据，最终满足「均值为 0，标准差为 1」的分布特性</li>
</ul>
<h3 id="dim-0-为啥是对列归一化？"><a href="#dim-0-为啥是对列归一化？" class="headerlink" title="dim&#x3D;0,为啥是对列归一化？"></a>dim&#x3D;0,为啥是对列归一化？</h3><p>dim为0按列，为1按行</p>
<p><strong>归一化的本质是对「特征」做预处理，每一列对应一个独立特征，每一行对应一个样本的特征集合，按列归一化是符合深度学习 &#x2F; 机器学习逻辑的必然选择，按行归一化无实际业务和模型意义</strong>。</p>
<h3 id="keepdim-True的作用？"><a href="#keepdim-True的作用？" class="headerlink" title="keepdim&#x3D;True的作用？"></a><strong>keepdim&#x3D;True</strong>的作用？</h3><p>keepdim默认为false，即计算过程中压缩计算维度为1维，会使维度不匹配而报错。令其为true可使张量维度保持不变。</p>
<h3 id="assert在这里的作用？"><a href="#assert在这里的作用？" class="headerlink" title="assert在这里的作用？"></a>assert在这里的作用？</h3><p>保险措施，<strong>强制校验特征维度</strong>，提前暴露特征筛选错误，避免后续模型训练时出现维度不匹配异常。</p>
<p><code>self.data.shape[1]</code>：获取归一化后特征张量的列数（即实际筛选得到的特征维度），<code>self.data.shape[0]</code> 是样本数；<code>feature_dim</code>：用户指定的目标特征维度（k，即要保留的重要特征数）；</p>
<p>assert 断言的作用：<br>若 feature_dim &#x3D;&#x3D; self.data.shape[1]（维度一致），程序正常继续执行；<br>若维度不一致（如 col_indices 筛选了 3 个特征，但 feature_dim&#x3D;5），立即抛出 AssertionError 异常，终止程序运行；</p>
<h2 id="第五，getitem和len"><a href="#第五，getitem和len" class="headerlink" title="第五，getitem和len"></a>第五，getitem和len</h2><p><strong>支持通过下标（索引）<code>item</code> 读取数据集对应位置的数据</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.mode == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[item].<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[item].<span class="built_in">float</span>(),<span class="variable language_">self</span>.y[item].<span class="built_in">float</span>()</span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)                 <span class="comment"># 返回数据长度。</span></span><br></pre></td></tr></table></figure>

<h2 id="另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset-nn-Module"><a href="#另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset-nn-Module" class="headerlink" title="另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset,nn.Module"></a>另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset,nn.Module</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">myNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,inDim</span>):</span><br><span class="line">        <span class="built_in">super</span>(myNet,<span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(inDim, <span class="number">64</span>)              <span class="comment"># 全连接</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()                      <span class="comment"># 激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">64</span>,<span class="number">1</span>)                  <span class="comment"># 全连接</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">covidDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path, mode=<span class="string">&quot;train&quot;</span>, feature_dim=<span class="number">5</span>, all_feature=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            csv_data = <span class="built_in">list</span>(csv.reader(f))</span><br><span class="line">            column = csv_data[<span class="number">0</span>]</span><br><span class="line">            x = np.array(csv_data)[<span class="number">1</span>:,<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">            y = np.array(csv_data)[<span class="number">1</span>:,-<span class="number">1</span>]</span><br><span class="line">   </span><br></pre></td></tr></table></figure>

<h3 id="为啥Module要super，Dataset却不用？"><a href="#为啥Module要super，Dataset却不用？" class="headerlink" title="为啥Module要super，Dataset却不用？"></a>为啥Module要super，Dataset却不用？</h3><p>因为Dataset并没有用到什么高级的方法，都是我自己定义的。</p>
<p>而myNet需要用到Module基类里的高级方法，如果不super，模型就识别不出fc1、relu、fc2有何意味。</p>
<p>super的用法：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>().__init__()</span><br></pre></td></tr></table></figure>

<h2 id="第六，前向传播"><a href="#第六，前向传播" class="headerlink" title="第六，前向传播"></a>第六，前向传播</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">    x = <span class="variable language_">self</span>.fc1(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(x.size()) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> x.squeeze(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<h3 id="squeeze起什么作用？不是已经被压缩到一维了吗？"><a href="#squeeze起什么作用？不是已经被压缩到一维了吗？" class="headerlink" title="squeeze起什么作用？不是已经被压缩到一维了吗？"></a>squeeze起什么作用？不是已经被压缩到一维了吗？</h3><p>虽然self.fc2 &#x3D; nn.Linear(64,1)确实把维度降到了一，但实际上还是形状为(样本数量，1)的二维张量。这让结果看起来是一个n*1的矩阵，而squeeze的作用就是把结果转换为大小为n的一维数组</p>
<h2 id="第七，模型训练验证中的训练部分"><a href="#第七，模型训练验证中的训练部分" class="headerlink" title="第七，模型训练验证中的训练部分"></a>第七，模型训练验证中的训练部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_val</span>(<span class="params">model, trainloader, valloader, optimizer, loss ,epoch,device,save_</span>)</span><br><span class="line">    model =model.to(device)</span><br><span class="line">    plt_train_loss = []</span><br><span class="line">    plt_val_loss = []</span><br><span class="line">    val_rel = []</span><br><span class="line">    min_val_loss = <span class="number">1000000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        strat_time = time.time()</span><br><span class="line">        model.train()</span><br><span class="line">        train_loss = <span class="number">0.0</span></span><br><span class="line">        val_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> trainloader:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            x, target = data[<span class="number">0</span>].to(device),data[<span class="number">1</span>].to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line">            bat_loss = loss(pred,target,model)</span><br><span class="line">            optimizer.step()</span><br><span class="line">            train_loss += bat_loss.detach().cpu().item()</span><br><span class="line">     plt_train_loss. append(train_loss/trainloader.dataset.__len__())</span><br></pre></td></tr></table></figure>

<h3 id="这些参数分别啥意思？"><a href="#这些参数分别啥意思？" class="headerlink" title="这些参数分别啥意思？"></a>这些参数分别啥意思？</h3><p>model模型, trainloader训练集数据, valloader验证集数据, </p>
<p>optimizer动态调整梯度的调节方向和调节速率，通过学习率控制,</p>
<p> loss 损失,epoch训练轮次,device设备,save_保存到哪里</p>
<h3 id="model-model-to-device-什么作用？"><a href="#model-model-to-device-什么作用？" class="headerlink" title="model &#x3D;model.to(device)什么作用？"></a>model &#x3D;model.to(device)什么作用？</h3><p>把模型搬到同一个设备上，保证在同一块CPU或者GPU上运行</p>
<h3 id="optimizer-zero-grad-？"><a href="#optimizer-zero-grad-？" class="headerlink" title="optimizer.zero_grad()？"></a>optimizer.zero_grad()？</h3><p>清空每一批数据的梯度，防止被传到下一批中影响结果，导致参数更新错误</p>
<p>梯度可以类比学生错在哪里的错题分析。如果新的一轮不清除上一轮的错题分析，会影响新一轮批次的梯度。</p>
<h3 id="pred-model-x-？"><a href="#pred-model-x-？" class="headerlink" title="pred &#x3D; model(x)？"></a>pred &#x3D; model(x)？</h3><p>model(x) 会自动触发 model.forward(x) 方法，这是 PyTorch 帮我们封装好的便捷操作</p>
<p>把输入数据 x 传入模型，让模型按照你定义的 forward 方法执行计算，最终返回预测结果 pred（存到 pred 变量里）。</p>
<h3 id="bat-loss-loss-pred-target-model"><a href="#bat-loss-loss-pred-target-model" class="headerlink" title="bat_loss &#x3D; loss(pred,target,model)"></a>bat_loss &#x3D; loss(pred,target,model)</h3><p>即batch_loss，loss()是函数传入的损失函数，且得到的结果是一个一维张量，想要使用他还要转成数字</p>
<h3 id="trainloader-dataset-len"><a href="#trainloader-dataset-len" class="headerlink" title="trainloader.dataset.len()"></a>trainloader.dataset.<strong>len</strong>()</h3><p>记录每一轮训练的平均损失值，为后续绘制损失曲线做准备。训练集的 “总题数”（总样本数）</p>
<h2 id="第八，模型训练验证中的验证部分"><a href="#第八，模型训练验证中的验证部分" class="headerlink" title="第八，模型训练验证中的验证部分"></a>第八，模型训练验证中的验证部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> valloader:</span><br><span class="line">                val_x, val_target = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">                val_pred = model(val_x)</span><br><span class="line">                val_bat_loss = loss(val_pred,val_target,model)</span><br><span class="line">                val_loss += val_bat_loss.detach().cpu().item()</span><br><span class="line">        <span class="keyword">if</span> val_loss &lt; min_val_loss:</span><br><span class="line">            torch.save(model, save_)</span><br><span class="line">        plt_val_loss.append(val_loss/valloader.dataset.__len__())</span><br></pre></td></tr></table></figure>

<h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><p>第一、model切换训练模式是model.train(),但切换验证模式是eval()而不是val()</p>
<p>第二、若得到了更小的损失，torch.save(model, save_)保存的是模型</p>
</article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta"><i class="fas fa-circle-user fa-fw"></i>文章作者: </span><span class="post-copyright-info"><a href="http://example.com">线粒体donut</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta"><i class="fas fa-square-arrow-up-right fa-fw"></i>文章链接: </span><span class="post-copyright-info"><a href="http://example.com/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/">http://example.com/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta"><i class="fas fa-circle-exclamation fa-fw"></i>版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来源 <a href="http://example.com" target="_blank">何意味</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%9B%9E%E5%BD%92/">回归</a></div><div class="post-share"><div class="social-share" data-image="/img/picture.jpg" data-sites="facebook,x,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/css/share.min.css" media="print" onload="this.media='all'"><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1.1.6/sharejs/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i>赞助</div><div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/img/wechat.jpg" target="_blank"><img class="post-qr-code-img" src="/img/wechat.jpg" alt="微信"/></a><div class="post-qr-code-desc">微信</div></li><li class="reward-item"><a href="/img/alipay.jpg" target="_blank"><img class="post-qr-code-img" src="/img/alipay.jpg" alt="支付宝"/></a><div class="post-qr-code-desc">支付宝</div></li></ul></div></div><nav class="pagination-post" id="pagination"><a class="pagination-related" href="/2026/01/01/with%E7%9A%84%E7%94%A8%E6%B3%95/" title="with的用法"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info"><div class="info-1"><div class="info-item-1">上一篇</div><div class="info-item-2">with的用法</div></div><div class="info-2"><div class="info-item-1">用法一：文件如果不使用with，我们应该如何打开一个文件？12345678910try:    # 1. [进入]    f = open(&#x27;a.txt&#x27;, &#x27;r&#x27;, encoding=&quot;utf-8&quot;)    # 2. [执行]    print(f.read())finally:    if f:        # 3. [退出]        f.close()  with在这里就起到一个封装try和finally的作用，finally的作用就是如果文件在io过程中产生了错误，也能正常执行f.close()安全关闭文件 写成with语句12with open(&quot;a.txt&quot;, &quot;r&quot;, encoding=&quot;utf-8&quot;) as f:    print(f.read())  即把open(“a.txt”, “r”, encoding&#x3D;”utf-8”)的结果命名为f，再执行print(f.read())的语句块。 用法二：pytorch梯度管理with...</div></div></div></a><a class="pagination-related" href="/2025/12/30/hello-world/" title="Hello World"><div class="cover" style="background: var(--default-bg-color)"></div><div class="info text-right"><div class="info-1"><div class="info-item-1">下一篇</div><div class="info-item-2">Hello World</div></div><div class="info-2"><div class="info-item-1">Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot;  More info: Writing Run server1$ hexo server  More info: Server Generate static files1$ hexo generate  More info: Generating Deploy to remote sites1$ hexo deploy  More info: Deployment </div></div></div></a></nav></div><div class="aside-content" id="aside-content"><div class="card-widget card-info text-center"><div class="avatar-img"><img src="/img/picture.jpg" onerror="this.onerror=null;this.src='/img/friend_404.gif'" alt="avatar"/></div><div class="author-info-name">线粒体donut</div><div class="author-info-description">逆转时间的公式是珍惜当下</div><div class="site-data"><a href="/archives/"><div class="headline">文章</div><div class="length-num">3</div></a><a href="/tags/"><div class="headline">标签</div><div class="length-num">2</div></a><a href="/categories/"><div class="headline">分类</div><div class="length-num">2</div></a></div><a id="card-info-btn" target="_blank" rel="noopener" href="https://github.com/xxxxxx"><i class="fab fa-github"></i><span>就是今天</span></a></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn fa-shake"></i><span>公告</span></div><div class="announcement_content">这家伙不懒，但依旧什么都没有留下</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span><span class="toc-percentage"></span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86%EF%BC%9A%E5%88%9D%E5%A7%8B%E5%8C%96"><span class="toc-number">1.</span> <span class="toc-text">第一部分：初始化</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%80%EF%BC%8C%E6%89%93%E5%BC%80%E6%96%87%E4%BB%B6"><span class="toc-number">1.1.</span> <span class="toc-text">第一，打开文件</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E3%80%81with-open-file-train-%E2%80%9Dr%E2%80%9D-as-f%E4%B8%AD%E7%9A%84with%E5%92%8Cas-f%E6%98%AF%E5%B9%B2%E5%98%9B%E7%94%A8%E7%9A%84%EF%BC%9F"><span class="toc-number">1.1.1.</span> <span class="toc-text">一、with open(file_train,”r”) as f中的with和as f是干嘛用的？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%BA%8C%E3%80%81%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81list-%EF%BC%9F"><span class="toc-number">1.1.2.</span> <span class="toc-text">二、为什么需要list()？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%8C%EF%BC%8C%E7%89%B9%E5%BE%81%E7%AD%9B%E9%80%89%EF%BC%88%E5%8F%AF%E9%80%89%EF%BC%89"><span class="toc-number">1.2.</span> <span class="toc-text">第二，特征筛选（可选）</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#feature-data-label-data%E5%88%86%E5%88%AB%E6%98%AF%E4%BB%80%E4%B9%88%E5%8F%82%E6%95%B0%EF%BC%9F"><span class="toc-number">1.2.1.</span> <span class="toc-text">feature_data, label_data分别是什么参数？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%89%EF%BC%8C%E6%8B%86%E5%88%86%E6%95%B0%E6%8D%AE%E9%9B%86%EF%BC%88%E5%8F%AA%E5%A4%84%E7%90%86%E4%BA%86y%EF%BC%89"><span class="toc-number">1.3.</span> <span class="toc-text">第三，拆分数据集（只处理了y）</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%9B%9B%EF%BC%8C%E7%89%B9%E5%BE%81%E6%8F%90%E5%8F%96%EF%BC%88%E5%A4%84%E7%90%86x%EF%BC%89%EF%BC%8C%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%8C%E6%A0%A1%E9%AA%8C"><span class="toc-number">1.4.</span> <span class="toc-text">第四，特征提取（处理x），归一化，校验</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%9F"><span class="toc-number">1.4.1.</span> <span class="toc-text">归一化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#dim-0-%E4%B8%BA%E5%95%A5%E6%98%AF%E5%AF%B9%E5%88%97%E5%BD%92%E4%B8%80%E5%8C%96%EF%BC%9F"><span class="toc-number">1.4.2.</span> <span class="toc-text">dim&#x3D;0,为啥是对列归一化？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#keepdim-True%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">1.4.3.</span> <span class="toc-text">keepdim&#x3D;True的作用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#assert%E5%9C%A8%E8%BF%99%E9%87%8C%E7%9A%84%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">1.4.4.</span> <span class="toc-text">assert在这里的作用？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%BA%94%EF%BC%8Cgetitem%E5%92%8Clen"><span class="toc-number">1.5.</span> <span class="toc-text">第五，getitem和len</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%8F%A6%E5%A4%96%EF%BC%8C%E7%B1%BB%E7%9A%84%E4%B9%A6%E5%86%99%E5%92%8C%E5%87%BD%E6%95%B0%E4%B8%8D%E4%B8%80%E6%A0%B7%EF%BC%8C%E7%B1%BB%E4%BC%9A%E8%B0%83%E7%94%A8%E6%8B%AC%E5%8F%B7%E9%87%8C%E9%9D%A2%E7%9A%84%E5%9F%BA%E7%B1%BB%EF%BC%8C%E5%A6%82Dataset-nn-Module"><span class="toc-number">1.6.</span> <span class="toc-text">另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset,nn.Module</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%BA%E5%95%A5Module%E8%A6%81super%EF%BC%8CDataset%E5%8D%B4%E4%B8%8D%E7%94%A8%EF%BC%9F"><span class="toc-number">1.6.1.</span> <span class="toc-text">为啥Module要super，Dataset却不用？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AD%EF%BC%8C%E5%89%8D%E5%90%91%E4%BC%A0%E6%92%AD"><span class="toc-number">1.7.</span> <span class="toc-text">第六，前向传播</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#squeeze%E8%B5%B7%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%EF%BC%9F%E4%B8%8D%E6%98%AF%E5%B7%B2%E7%BB%8F%E8%A2%AB%E5%8E%8B%E7%BC%A9%E5%88%B0%E4%B8%80%E7%BB%B4%E4%BA%86%E5%90%97%EF%BC%9F"><span class="toc-number">1.7.1.</span> <span class="toc-text">squeeze起什么作用？不是已经被压缩到一维了吗？</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E4%B8%83%EF%BC%8C%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%AA%8C%E8%AF%81%E4%B8%AD%E7%9A%84%E8%AE%AD%E7%BB%83%E9%83%A8%E5%88%86"><span class="toc-number">1.8.</span> <span class="toc-text">第七，模型训练验证中的训练部分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%BF%99%E4%BA%9B%E5%8F%82%E6%95%B0%E5%88%86%E5%88%AB%E5%95%A5%E6%84%8F%E6%80%9D%EF%BC%9F"><span class="toc-number">1.8.1.</span> <span class="toc-text">这些参数分别啥意思？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#model-model-to-device-%E4%BB%80%E4%B9%88%E4%BD%9C%E7%94%A8%EF%BC%9F"><span class="toc-number">1.8.2.</span> <span class="toc-text">model &#x3D;model.to(device)什么作用？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#optimizer-zero-grad-%EF%BC%9F"><span class="toc-number">1.8.3.</span> <span class="toc-text">optimizer.zero_grad()？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#pred-model-x-%EF%BC%9F"><span class="toc-number">1.8.4.</span> <span class="toc-text">pred &#x3D; model(x)？</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#bat-loss-loss-pred-target-model"><span class="toc-number">1.8.5.</span> <span class="toc-text">bat_loss &#x3D; loss(pred,target,model)</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#trainloader-dataset-len"><span class="toc-number">1.8.6.</span> <span class="toc-text">trainloader.dataset.len()</span></a></li></ol></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%AC%AC%E5%85%AB%EF%BC%8C%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E9%AA%8C%E8%AF%81%E4%B8%AD%E7%9A%84%E9%AA%8C%E8%AF%81%E9%83%A8%E5%88%86"><span class="toc-number">1.9.</span> <span class="toc-text">第八，模型训练验证中的验证部分</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%B3%A8%E6%84%8F%E7%82%B9"><span class="toc-number">1.9.1.</span> <span class="toc-text">注意点</span></a></li></ol></li></ol></li></ol></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2026/01/01/with%E7%9A%84%E7%94%A8%E6%B3%95/" title="with的用法">with的用法</a><time datetime="2026-01-01T07:30:00.000Z" title="发表于 2026-01-01 15:30:00">2026-01-01</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/" title="深度学习项目实战第三节">深度学习项目实战第三节</a><time datetime="2025-12-30T03:19:54.000Z" title="发表于 2025-12-30 11:19:54">2025-12-30</time></div></div><div class="aside-list-item no-cover"><div class="content"><a class="title" href="/2025/12/30/hello-world/" title="Hello World">Hello World</a><time datetime="2025-12-30T02:01:55.153Z" title="发表于 2025-12-30 10:01:55">2025-12-30</time></div></div></div></div></div></div></main><footer id="footer"><div class="footer-other"><div class="footer-copyright"><span class="copyright">&copy;&nbsp;2025 - 2026 By 线粒体donut</span><span class="framework-info"><span>框架 </span><a target="_blank" rel="noopener" href="https://hexo.io">Hexo 8.1.1</a><span class="footer-separator">|</span><span>主题 </span><a target="_blank" rel="noopener" href="https://github.com/jerryc127/hexo-theme-butterfly">Butterfly 5.5.3</a></span></div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="darkmode" type="button" title="日间和夜间模式切换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside-config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="go-up" type="button" title="回到顶部"><span class="scroll-percent"></span><i class="fas fa-arrow-up"></i></button></div></div><div><script src="/js/utils.js?v=5.5.3"></script><script src="/js/main.js?v=5.5.3"></script><div class="js-pjax"></div><script async data-pjax src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><div id="local-search"><div class="search-dialog"><nav class="search-nav"><span class="search-dialog-title">搜索</span><i class="fas fa-spinner fa-pulse" id="loading-status" hidden="hidden"></i><button class="search-close-button"><i class="fas fa-times"></i></button></nav><div class="text-center" id="loading-database"><i class="fas fa-spinner fa-pulse"></i><span>  数据加载中</span></div><div class="local-search-input"><input placeholder="搜索文章ing..." type="text"/></div><hr/><div id="local-search-results"></div><div class="ais-Pagination" id="local-search-pagination" style="display:none;"><ul class="ais-Pagination-list"></ul></div><div id="local-search-stats"></div></div><div id="search-mask"></div><script src="/js/search/local-search.js?v=5.5.3"></script></div></div></body></html>