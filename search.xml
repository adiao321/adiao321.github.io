<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>with的用法</title>
      <link href="/2026/01/01/with%E7%9A%84%E7%94%A8%E6%B3%95/"/>
      <url>/2026/01/01/with%E7%9A%84%E7%94%A8%E6%B3%95/</url>
      
        <content type="html"><![CDATA[<h1 id="用法一：文件"><a href="#用法一：文件" class="headerlink" title="用法一：文件"></a>用法一：文件</h1><h2 id="如果不使用with，我们应该如何打开一个文件？"><a href="#如果不使用with，我们应该如何打开一个文件？" class="headerlink" title="如果不使用with，我们应该如何打开一个文件？"></a>如果不使用with，我们应该如何打开一个文件？</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">try</span>:</span><br><span class="line">    <span class="comment"># 1. [进入]</span></span><br><span class="line">    f = <span class="built_in">open</span>(<span class="string">&#x27;a.txt&#x27;</span>, <span class="string">&#x27;r&#x27;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>)</span><br><span class="line">    <span class="comment"># 2. [执行]</span></span><br><span class="line">    <span class="built_in">print</span>(f.read())</span><br><span class="line"><span class="keyword">finally</span>:</span><br><span class="line">    <span class="keyword">if</span> f:</span><br><span class="line">        <span class="comment"># 3. [退出]</span></span><br><span class="line">        f.close()</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>with在这里就起到一个封装try和finally的作用，finally的作用就是如果文件在io过程中产生了错误，也能正常执行f.close()安全关闭文件</p><h2 id="写成with语句"><a href="#写成with语句" class="headerlink" title="写成with语句"></a>写成with语句</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">with</span> <span class="built_in">open</span>(<span class="string">&quot;a.txt&quot;</span>, <span class="string">&quot;r&quot;</span>, encoding=<span class="string">&quot;utf-8&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">    <span class="built_in">print</span>(f.read())</span><br></pre></td></tr></table></figure><p>即把open(“a.txt”, “r”, encoding&#x3D;”utf-8”)的结果命名为f，再执行print(f.read())的语句块。</p><h1 id="用法二：pytorch梯度管理"><a href="#用法二：pytorch梯度管理" class="headerlink" title="用法二：pytorch梯度管理"></a>用法二：pytorch梯度管理</h1><p>with语句可以临时切换计算环境状态并自动恢复初始状态。<strong>由于在验证和测试的过程中都不需要积累梯度</strong>，模型切换到eval模式使用torch.no_grad()，说明临时切换到了禁用张量的自动梯度计算模式，在计算结束后会恢复到计算梯度的状态</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">model.train()</span><br><span class="line">      train_loss = <span class="number">0.0</span></span><br><span class="line">      val_loss = <span class="number">0.0</span></span><br><span class="line">      <span class="keyword">for</span> data <span class="keyword">in</span> trainloader:</span><br><span class="line">          optimizer.zero_grad()</span><br><span class="line">          x, target = data[<span class="number">0</span>].to(device),data[<span class="number">1</span>].to(device)</span><br><span class="line">          pred = model(x)</span><br><span class="line">          bat_loss = loss(pred,target,model)</span><br><span class="line">          optimizer.step()</span><br><span class="line">          train_loss += bat_loss.detach().cpu().item()</span><br><span class="line">      plt_train_loss.append(train_loss/trainloader.dataset.__len__())</span><br><span class="line"></span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">      </span><br><span class="line">      <span class="comment"># 切换到验证模式</span></span><br><span class="line">      model.<span class="built_in">eval</span>()</span><br><span class="line">      <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">          <span class="keyword">for</span> data <span class="keyword">in</span> valloader:</span><br><span class="line">              val_x, val_target = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">              val_pred = model(val_x)</span><br><span class="line">              val_bat_loss = loss(val_pred,val_target,model)</span><br><span class="line">              val_loss += val_bat_loss.detach().cpu().item()</span><br><span class="line">      <span class="keyword">if</span> val_loss &lt; min_val_loss:</span><br><span class="line">          torch.save(model, save_)</span><br><span class="line">      plt_val_loss.append(val_loss/valloader.dataset.__len__())</span><br><span class="line"></span><br></pre></td></tr></table></figure><h1 id="总结："><a href="#总结：" class="headerlink" title="总结："></a>总结：</h1><p>with 语句核心：Python 上下文管理器语法糖，自动初始化 + 自动收尾，异常安全。</p><p>两大核心用法：</p><p>文件操作：with open(…) as f<br>自动打开 &#x2F; 关闭文件，避免句柄泄露，替代繁琐的 try…finally。</p><p>PyTorch 梯度管理：with torch.no_grad()<br>验证 &#x2F; 测试阶段临时禁用梯度计算，自动恢复状态，需与 model.eval() 搭配，节省资源 + 提速。</p>]]></content>
      
      
      <categories>
          
          <category> python语法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> with语句 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>深度学习项目实战第三节</title>
      <link href="/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/"/>
      <url>/2025/12/30/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E5%AE%9E%E6%88%98%E7%AC%AC%E4%B8%89%E8%8A%82/</url>
      
        <content type="html"><![CDATA[<p>首先我们要新建一个类，一个类里面要有三部分</p><h1 id="第一部分：初始化"><a href="#第一部分：初始化" class="headerlink" title="第一部分：初始化"></a>第一部分：初始化</h1><h2 id="第一，打开文件"><a href="#第一，打开文件" class="headerlink" title="第一，打开文件"></a>第一，打开文件</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">____________</span>):</span><br><span class="line">    <span class="keyword">with</span> <span class="built_in">open</span>(file_train,<span class="string">&quot;r&quot;</span>) <span class="keyword">as</span> f:</span><br><span class="line">        csv_data = <span class="built_in">list</span>(csv.reader(file_train))</span><br><span class="line">        column = csv_data[<span class="number">0</span>]</span><br><span class="line">        x = csv_data[<span class="number">1</span>:, <span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">        y = csv_data[<span class="number">1</span>:, -<span class="number">1</span>]</span><br></pre></td></tr></table></figure><h3 id="一、with-open-file-train-”r”-as-f中的with和as-f是干嘛用的？"><a href="#一、with-open-file-train-”r”-as-f中的with和as-f是干嘛用的？" class="headerlink" title="一、with open(file_train,”r”) as f中的with和as f是干嘛用的？"></a>一、with open(file_train,”r”) as f中的with和as f是干嘛用的？</h3><p>with：自动关闭文件。相当于open()打开而自动使用close()关闭。若只open不close，会导致文件一直被程序占用，其他程序无法打开导致内存泄漏。</p><p>as f：相当于给文件命名</p><h3 id="二、为什么需要list-？"><a href="#二、为什么需要list-？" class="headerlink" title="二、为什么需要list()？"></a>二、为什么需要list()？</h3><p>因为csv.reader()的作用是按照行分隔符（“&#x2F;n”）和列分隔符（“，”）做切割，如</p><p><img src="/images/1.png" alt="image-20251230181802459"></p><p>但这个功能是一个迭代器，只能单向遍历一次，不能索引，故需要转换成list以便于直接访问</p><h2 id="第二，特征筛选（可选）"><a href="#第二，特征筛选（可选）" class="headerlink" title="第二，特征筛选（可选）"></a>第二，特征筛选（可选）</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">get_feature_importance</span>(<span class="params">feature_data, label_data, k =<span class="number">4</span>,column = <span class="literal">None</span></span>):</span><br><span class="line">    model = SelectKBest(chi2, k=k)      <span class="comment">#定义一个选择k个最佳特征的函数</span></span><br><span class="line">    feature_data = np.array(feature_data, dtype=np.float64)</span><br><span class="line">    X_new = model.fit_transform(feature_data, label_data)   <span class="comment">#用这个函数选择k个最佳特征</span></span><br><span class="line">    <span class="comment">#feature_data是特征数据，label_data是标签数据，该函数可以选择出k个特征</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;x_new&#x27;</span>, X_new)</span><br><span class="line">    scores = model.scores_                <span class="comment"># scores即每一列与结果的相关性</span></span><br><span class="line">    <span class="comment"># 按重要性排序，选出最重要的 k 个</span></span><br><span class="line">    indices = np.argsort(scores)[::-<span class="number">1</span>]        <span class="comment">#[::-1]表示反转一个列表或者矩阵。</span></span><br><span class="line">    <span class="comment"># argsort这个函数， 可以矩阵排序后的下标。 比如 indices[0]表示的是，scores中最小值的下标。</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> column:                            <span class="comment"># 如果需要打印选中的列</span></span><br><span class="line">        k_best_features = [column[i+<span class="number">1</span>] <span class="keyword">for</span> i <span class="keyword">in</span> indices[<span class="number">0</span>:k].tolist()]         <span class="comment"># 选中这些列 打印</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;k best features are: &#x27;</span>,k_best_features)</span><br><span class="line">    <span class="keyword">return</span> X_new, indices[<span class="number">0</span>:k]                  <span class="comment"># 返回选中列的特征和他们的下标。</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">            <span class="keyword">if</span> all_feature:</span><br><span class="line">                col_indices = np.array([i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">0</span>,<span class="number">93</span>)])</span><br><span class="line">                col_indices = col_indices.tolist()</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                _,col_indices = get_feature_importance(x,y,feature_dim,column)</span><br><span class="line">                col_indices = col_indices.tolist()</span><br><span class="line">                </span><br><span class="line">            csv_data = np.array(csv_data[<span class="number">1</span>:])[:, <span class="number">1</span>:].astype(<span class="built_in">float</span>)</span><br></pre></td></tr></table></figure><h3 id="feature-data-label-data分别是什么参数？"><a href="#feature-data-label-data分别是什么参数？" class="headerlink" title="feature_data, label_data分别是什么参数？"></a>feature_data, label_data分别是什么参数？</h3><p>是x和y，即用来训练的数据部分和用来训练的已知的训练结果标签</p><h2 id="第三，拆分数据集（只处理了y）"><a href="#第三，拆分数据集（只处理了y）" class="headerlink" title="第三，拆分数据集（只处理了y）"></a>第三，拆分数据集（只处理了y）</h2><p>训练集逢五取四，验证集逢五取一，测试集全取。</p><p>y是训练、验证的标签，由于是这个类里面其他函数也要用的部分，故用self.y变成全局的。由于要后续使用，故转换成tensor</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> mode == <span class="string">&quot;train&quot;</span>:</span><br><span class="line">    indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(csv_data)) <span class="keyword">if</span> i % <span class="number">5</span> !=<span class="number">0</span>]</span><br><span class="line">    <span class="variable language_">self</span>.y = torch.tensor(csv_data[indices,-<span class="number">1</span>])</span><br><span class="line"><span class="keyword">elif</span> mode == <span class="string">&quot;val&quot;</span>:</span><br><span class="line">    indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(csv_data)) <span class="keyword">if</span> i % <span class="number">5</span> ==<span class="number">0</span>]</span><br><span class="line">    <span class="variable language_">self</span>.y = torch.tensor(csv_data[indices,-<span class="number">1</span>])</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    indices = [i <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(csv_data))]</span><br></pre></td></tr></table></figure><h2 id="第四，特征提取（处理x），归一化，校验"><a href="#第四，特征提取（处理x），归一化，校验" class="headerlink" title="第四，特征提取（处理x），归一化，校验"></a>第四，特征提取（处理x），归一化，校验</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data = torch.tensor(csv_data[indices,:])<span class="comment"># 只取选中模式（训练、验证、测试）下的行</span></span><br><span class="line">data = torch.tensor(csv_data[:,col_indices])<span class="comment">#只取挑出来的列</span></span><br><span class="line"><span class="variable language_">self</span>.data = data</span><br><span class="line"><span class="variable language_">self</span>.mode = mode</span><br><span class="line"><span class="variable language_">self</span>.data = (<span class="variable language_">self</span>.data - <span class="variable language_">self</span>.data.mean(dim=<span class="number">0</span>,keepdim=<span class="literal">True</span>)) / <span class="variable language_">self</span>.data.std(dim=<span class="number">0</span>,keepdim=<span class="literal">True</span>)<span class="comment"># 归一化</span></span><br><span class="line"><span class="keyword">assert</span> feature_dim == <span class="variable language_">self</span>.data.shape[<span class="number">1</span>]</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished reading the &#123;&#125; set of COVID19 Dataset (&#123;&#125; samples found, each dim = &#123;&#125;)&#x27;</span>.<span class="built_in">format</span>(mode, <span class="built_in">len</span>(<span class="variable language_">self</span>.data), feature_dim))  <span class="comment"># 打印读了多少数据</span></span><br></pre></td></tr></table></figure><h3 id="归一化？"><a href="#归一化？" class="headerlink" title="归一化？"></a>归一化？</h3><p><strong>标准化（Z-Score）公式</strong></p><p>这段代码实现的归一化遵循严格的数学公式：</p><p>$X_{norm} &#x3D; \frac{X - \mu}{\sigma}$</p><p>其中：</p><ul><li><em>X</em>：原始特征数据（这里是 <code>self.data</code> 张量中的某个特征的所有样本值）</li><li><em>μ</em>（mu）：该特征的<strong>均值</strong>（所有样本在该特征上的平均值，对应代码中 <code>self.data.mean(dim=0, keepdim=True)</code>）</li><li><em>σ</em>（sigma）：该特征的<strong>标准差</strong>（所有样本在该特征上的离散程度，对应代码中 <code>self.data.std(dim=0, keepdim=True)</code>）</li><li><strong>X</strong>norm：标准化后的特征数据，最终满足「均值为 0，标准差为 1」的分布特性</li></ul><h3 id="dim-0-为啥是对列归一化？"><a href="#dim-0-为啥是对列归一化？" class="headerlink" title="dim&#x3D;0,为啥是对列归一化？"></a>dim&#x3D;0,为啥是对列归一化？</h3><p>dim为0按列，为1按行</p><p><strong>归一化的本质是对「特征」做预处理，每一列对应一个独立特征，每一行对应一个样本的特征集合，按列归一化是符合深度学习 &#x2F; 机器学习逻辑的必然选择，按行归一化无实际业务和模型意义</strong>。</p><h3 id="keepdim-True的作用？"><a href="#keepdim-True的作用？" class="headerlink" title="keepdim&#x3D;True的作用？"></a><strong>keepdim&#x3D;True</strong>的作用？</h3><p>keepdim默认为false，即计算过程中压缩计算维度为1维，会使维度不匹配而报错。令其为true可使张量维度保持不变。</p><h3 id="assert在这里的作用？"><a href="#assert在这里的作用？" class="headerlink" title="assert在这里的作用？"></a>assert在这里的作用？</h3><p>保险措施，<strong>强制校验特征维度</strong>，提前暴露特征筛选错误，避免后续模型训练时出现维度不匹配异常。</p><p><code>self.data.shape[1]</code>：获取归一化后特征张量的列数（即实际筛选得到的特征维度），<code>self.data.shape[0]</code> 是样本数；<code>feature_dim</code>：用户指定的目标特征维度（k，即要保留的重要特征数）；</p><p>assert 断言的作用：<br>若 feature_dim &#x3D;&#x3D; self.data.shape[1]（维度一致），程序正常继续执行；<br>若维度不一致（如 col_indices 筛选了 3 个特征，但 feature_dim&#x3D;5），立即抛出 AssertionError 异常，终止程序运行；</p><h2 id="第五，getitem和len"><a href="#第五，getitem和len" class="headerlink" title="第五，getitem和len"></a>第五，getitem和len</h2><p><strong>支持通过下标（索引）<code>item</code> 读取数据集对应位置的数据</strong></p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__getitem__</span>(<span class="params">self, item</span>):</span><br><span class="line">    <span class="keyword">if</span> <span class="variable language_">self</span>.mode == <span class="string">&quot;test&quot;</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[item].<span class="built_in">float</span>()</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> <span class="variable language_">self</span>.data[item].<span class="built_in">float</span>(),<span class="variable language_">self</span>.y[item].<span class="built_in">float</span>()</span><br><span class="line"> <span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">len</span>(<span class="variable language_">self</span>.data)                 <span class="comment"># 返回数据长度。</span></span><br></pre></td></tr></table></figure><h2 id="另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset-nn-Module"><a href="#另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset-nn-Module" class="headerlink" title="另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset,nn.Module"></a>另外，类的书写和函数不一样，类会调用括号里面的基类，如Dataset,nn.Module</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">myNet</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,inDim</span>):</span><br><span class="line">        <span class="built_in">super</span>(myNet,<span class="variable language_">self</span>).__init__()</span><br><span class="line">        <span class="variable language_">self</span>.fc1 = nn.Linear(inDim, <span class="number">64</span>)              <span class="comment"># 全连接</span></span><br><span class="line">        <span class="variable language_">self</span>.relu = nn.ReLU()                      <span class="comment"># 激活函数</span></span><br><span class="line">        <span class="variable language_">self</span>.fc2 = nn.Linear(<span class="number">64</span>,<span class="number">1</span>)                  <span class="comment"># 全连接</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">covidDataset</span>(<span class="title class_ inherited__">Dataset</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, path, mode=<span class="string">&quot;train&quot;</span>, feature_dim=<span class="number">5</span>, all_feature=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">with</span> <span class="built_in">open</span>(path,<span class="string">&#x27;r&#x27;</span>) <span class="keyword">as</span> f:</span><br><span class="line">            csv_data = <span class="built_in">list</span>(csv.reader(f))</span><br><span class="line">            column = csv_data[<span class="number">0</span>]</span><br><span class="line">            x = np.array(csv_data)[<span class="number">1</span>:,<span class="number">1</span>:-<span class="number">1</span>]</span><br><span class="line">            y = np.array(csv_data)[<span class="number">1</span>:,-<span class="number">1</span>]</span><br><span class="line">   </span><br></pre></td></tr></table></figure><h3 id="为啥Module要super，Dataset却不用？"><a href="#为啥Module要super，Dataset却不用？" class="headerlink" title="为啥Module要super，Dataset却不用？"></a>为啥Module要super，Dataset却不用？</h3><p>因为Dataset并没有用到什么高级的方法，都是我自己定义的。</p><p>而myNet需要用到Module基类里的高级方法，如果不super，模型就识别不出fc1、relu、fc2有何意味。</p><p>super的用法：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">super</span>().__init__()</span><br></pre></td></tr></table></figure><h2 id="第六，前向传播"><a href="#第六，前向传播" class="headerlink" title="第六，前向传播"></a>第六，前向传播</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">    x = <span class="variable language_">self</span>.fc1(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.relu(x)</span><br><span class="line">    x = <span class="variable language_">self</span>.fc2(x)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(x.size()) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> x.squeeze(<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure><h3 id="squeeze起什么作用？不是已经被压缩到一维了吗？"><a href="#squeeze起什么作用？不是已经被压缩到一维了吗？" class="headerlink" title="squeeze起什么作用？不是已经被压缩到一维了吗？"></a>squeeze起什么作用？不是已经被压缩到一维了吗？</h3><p>虽然self.fc2 &#x3D; nn.Linear(64,1)确实把维度降到了一，但实际上还是形状为(样本数量，1)的二维张量。这让结果看起来是一个n*1的矩阵，而squeeze的作用就是把结果转换为大小为n的一维数组</p><h2 id="第七，模型训练验证中的训练部分"><a href="#第七，模型训练验证中的训练部分" class="headerlink" title="第七，模型训练验证中的训练部分"></a>第七，模型训练验证中的训练部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">train_val</span>(<span class="params">model, trainloader, valloader, optimizer, loss ,epoch,device,save_</span>)</span><br><span class="line">    model =model.to(device)</span><br><span class="line">    plt_train_loss = []</span><br><span class="line">    plt_val_loss = []</span><br><span class="line">    val_rel = []</span><br><span class="line">    min_val_loss = <span class="number">1000000</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(epoch):</span><br><span class="line">        strat_time = time.time()</span><br><span class="line">        model.train()</span><br><span class="line">        train_loss = <span class="number">0.0</span></span><br><span class="line">        val_loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> data <span class="keyword">in</span> trainloader:</span><br><span class="line">            optimizer.zero_grad()</span><br><span class="line">            x, target = data[<span class="number">0</span>].to(device),data[<span class="number">1</span>].to(device)</span><br><span class="line">            pred = model(x)</span><br><span class="line">            bat_loss = loss(pred,target,model)</span><br><span class="line">            optimizer.step()</span><br><span class="line">            train_loss += bat_loss.detach().cpu().item()</span><br><span class="line">     plt_train_loss. append(train_loss/trainloader.dataset.__len__())</span><br></pre></td></tr></table></figure><h3 id="这些参数分别啥意思？"><a href="#这些参数分别啥意思？" class="headerlink" title="这些参数分别啥意思？"></a>这些参数分别啥意思？</h3><p>model模型, trainloader训练集数据, valloader验证集数据, </p><p>optimizer动态调整梯度的调节方向和调节速率，通过学习率控制,</p><p> loss 损失,epoch训练轮次,device设备,save_保存到哪里</p><h3 id="model-model-to-device-什么作用？"><a href="#model-model-to-device-什么作用？" class="headerlink" title="model &#x3D;model.to(device)什么作用？"></a>model &#x3D;model.to(device)什么作用？</h3><p>把模型搬到同一个设备上，保证在同一块CPU或者GPU上运行</p><h3 id="optimizer-zero-grad-？"><a href="#optimizer-zero-grad-？" class="headerlink" title="optimizer.zero_grad()？"></a>optimizer.zero_grad()？</h3><p>清空每一批数据的梯度，防止被传到下一批中影响结果，导致参数更新错误</p><p>梯度可以类比学生错在哪里的错题分析。如果新的一轮不清除上一轮的错题分析，会影响新一轮批次的梯度。</p><h3 id="pred-model-x-？"><a href="#pred-model-x-？" class="headerlink" title="pred &#x3D; model(x)？"></a>pred &#x3D; model(x)？</h3><p>model(x) 会自动触发 model.forward(x) 方法，这是 PyTorch 帮我们封装好的便捷操作</p><p>把输入数据 x 传入模型，让模型按照你定义的 forward 方法执行计算，最终返回预测结果 pred（存到 pred 变量里）。</p><h3 id="bat-loss-loss-pred-target-model"><a href="#bat-loss-loss-pred-target-model" class="headerlink" title="bat_loss &#x3D; loss(pred,target,model)"></a>bat_loss &#x3D; loss(pred,target,model)</h3><p>即batch_loss，loss()是函数传入的损失函数，且得到的结果是一个一维张量，想要使用他还要转成数字</p><h3 id="trainloader-dataset-len"><a href="#trainloader-dataset-len" class="headerlink" title="trainloader.dataset.len()"></a>trainloader.dataset.<strong>len</strong>()</h3><p>记录每一轮训练的平均损失值，为后续绘制损失曲线做准备。训练集的 “总题数”（总样本数）</p><h2 id="第八，模型训练验证中的验证部分"><a href="#第八，模型训练验证中的验证部分" class="headerlink" title="第八，模型训练验证中的验证部分"></a>第八，模型训练验证中的验证部分</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">model.<span class="built_in">eval</span>()</span><br><span class="line">        <span class="keyword">with</span> torch.no_grad():</span><br><span class="line">            <span class="keyword">for</span> data <span class="keyword">in</span> valloader:</span><br><span class="line">                val_x, val_target = data[<span class="number">0</span>].to(device), data[<span class="number">1</span>].to(device)</span><br><span class="line">                val_pred = model(val_x)</span><br><span class="line">                val_bat_loss = loss(val_pred,val_target,model)</span><br><span class="line">                val_loss += val_bat_loss.detach().cpu().item()</span><br><span class="line">        <span class="keyword">if</span> val_loss &lt; min_val_loss:</span><br><span class="line">            torch.save(model, save_)</span><br><span class="line">        plt_val_loss.append(val_loss/valloader.dataset.__len__())</span><br></pre></td></tr></table></figure><h3 id="注意点"><a href="#注意点" class="headerlink" title="注意点"></a>注意点</h3><p>第一、model切换训练模式是model.train(),但切换验证模式是eval()而不是val()</p><p>第二、若得到了更小的损失，torch.save(model, save_)保存的是模型</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 回归 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Hello World</title>
      <link href="/2025/12/30/hello-world/"/>
      <url>/2025/12/30/hello-world/</url>
      
        <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
